---
phase: 02-cost-analytics
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - src/tributary/analytics/impact.py
  - src/tributary/analytics/__init__.py
  - tests/unit/test_impact.py
autonomous: true

must_haves:
  truths:
    - "User can estimate temporary market impact from historical data"
    - "User can estimate permanent market impact from historical data"
    - "Impact model warns when participation rate is too high for reliable estimates"
    - "Model provides confidence level based on market conditions"
  artifacts:
    - path: "src/tributary/analytics/impact.py"
      provides: "Market impact estimation (temporary and permanent)"
      exports: ["ImpactEstimate", "estimate_market_impact", "calibrate_impact_parameters"]
    - path: "tests/unit/test_impact.py"
      provides: "Unit tests for impact estimation"
      min_tests: 15
  key_links:
    - from: "src/tributary/analytics/__init__.py"
      to: "impact.py"
      via: "module exports"
      pattern: "from tributary.analytics import estimate_market_impact, ImpactEstimate"
---

<objective>
Implement market impact estimation using the square-root model with temporary/permanent decomposition.

Purpose: Provide model-based impact forecasting as SECONDARY validation to orderbook-based estimates. The square-root law (Almgren et al. 2005) is well-established for equity markets. For thin liquidity markets like Polymarket, this serves as a sanity check, not primary truth. Also provides parameter calibration from historical execution data for Phase 3 Almgren-Chriss optimization.

Output: impact.py module with square-root impact model, temporary/permanent decomposition, and parameter calibration via OLS regression.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/02-cost-analytics/02-RESEARCH.md

# Phase 1 deliverables
@src/tributary/analytics/reader.py
@src/tributary/analytics/__init__.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Square-Root Impact Model</name>
  <files>
    src/tributary/analytics/impact.py
    tests/unit/test_impact.py
  </files>
  <action>
Create `impact.py` with:

1. `ImpactEstimate` dataclass:
   ```python
   @dataclass
   class ImpactEstimate:
       temporary_impact_bps: float   # Reverts after execution
       permanent_impact_bps: float   # Persists (information content)
       total_impact_bps: float       # temporary + permanent + spread
       confidence: str               # 'HIGH', 'MEDIUM', 'LOW'
       notes: List[str]              # Warnings and context
   ```

2. `estimate_market_impact()` function (from 02-RESEARCH.md Pattern 4):
   - Parameters: order_size, daily_volume, volatility (decimal), spread_bps, alpha (default 0.5)
   - Formula: temporary_impact = volatility * (order_size / daily_volume)^alpha * 10000
   - Permanent impact: 40% of temporary (conservative default for thin markets)
   - Add half-spread as execution cost
   - Confidence logic:
     - participation_rate > 10%: LOW confidence, add warning note
     - participation_rate 1-10%: MEDIUM confidence
     - participation_rate < 1%: HIGH confidence
   - Return ImpactEstimate dataclass
   - Handle edge cases: zero/negative daily_volume returns NaN with LOW confidence

3. Include prominent docstring WARNING that this model is calibrated for equity markets and should be used as SECONDARY validation for thin liquidity prediction markets.

Create `test_impact.py` with tests (for Task 1):
- Small order (low participation rate) - HIGH confidence
- Medium order (1-10% participation) - MEDIUM confidence
- Large order (>10% participation) - LOW confidence with warning
- Zero daily volume returns NaN
- Temporary vs permanent ratio check
- Alpha = 0.5 (square-root) produces expected values
- Alpha = 0.6 produces higher impact
- Spread component added correctly
- Notes populated for elevated participation
- Total = temporary + permanent + half-spread
  </action>
  <verify>
    - `python -c "from tributary.analytics.impact import estimate_market_impact, ImpactEstimate; print(estimate_market_impact(1000, 100000, 0.02, 50))"`
    - Output should show ImpactEstimate with all fields populated
    - `pytest tests/unit/test_impact.py::test_small_order -v` passes
  </verify>
  <done>
    - ImpactEstimate dataclass with temporary, permanent, total, confidence, notes
    - estimate_market_impact implements square-root model with confidence levels
    - Appropriate warnings for high participation rates
    - 10+ unit tests for impact estimation passing
  </done>
</task>

<task type="auto">
  <name>Task 2: Impact Parameter Calibration</name>
  <files>
    src/tributary/analytics/impact.py
    tests/unit/test_impact.py
    src/tributary/analytics/__init__.py
  </files>
  <action>
Add to `impact.py`:

1. `CalibrationResult` dataclass:
   ```python
   @dataclass
   class CalibrationResult:
       alpha: float                  # Impact exponent (0.5 = square-root)
       volatility_sensitivity: float # Beta for volatility term
       intercept: float              # Regression constant
       r_squared: float              # Model fit quality
       alpha_std_error: float        # Uncertainty in alpha estimate
       n_observations: int           # Number of data points used
       warnings: List[str]           # Data quality warnings
   ```

2. `calibrate_impact_parameters()` function (from 02-RESEARCH.md Pattern 5):
   - Parameters: executions_df (DataFrame with order_size, daily_volume, realized_impact_bps, volatility)
   - Uses statsmodels OLS regression:
     - log(impact) ~ c + alpha*log(participation) + beta*log(volatility)
   - Filter out zero/negative values before regression
   - Minimum 10 observations required
   - Return CalibrationResult with model diagnostics
   - Add warnings if:
     - alpha_std_error > 0.3 (unreliable estimate)
     - r_squared < 0.3 (poor model fit)
     - n_observations < 30 (limited data)

3. Update `__init__.py` to export:
   - `ImpactEstimate`, `estimate_market_impact`
   - `CalibrationResult`, `calibrate_impact_parameters`

Add tests to `test_impact.py`:
- Calibration with synthetic data (known alpha = 0.5)
- Calibration with insufficient data (< 10 points) returns error
- Calibration filters zero values
- Calibration returns warnings for poor fit
- Calibration returns warnings for high std_error
- r_squared and alpha_std_error populated correctly

Follow research code patterns and use statsmodels as specified.
  </action>
  <verify>
    - `python -c "from tributary.analytics import calibrate_impact_parameters, CalibrationResult; print('OK')"`
    - `pytest tests/unit/test_impact.py -v` passes all tests (15+)
    - `ruff check src/tributary/analytics/` passes
  </verify>
  <done>
    - CalibrationResult dataclass with regression diagnostics
    - calibrate_impact_parameters uses statsmodels OLS
    - Appropriate warnings for data quality issues
    - All exports available from analytics package
    - 15+ unit tests passing
    - Requirements COST-06, COST-07 satisfied
  </done>
</task>

</tasks>

<verification>
After completing both tasks:
1. All 15+ unit tests pass: `pytest tests/unit/test_impact.py -v`
2. Imports work cleanly: `from tributary.analytics import ImpactEstimate, estimate_market_impact, CalibrationResult, calibrate_impact_parameters`
3. Lint passes: `ruff check src/tributary/analytics/`
4. statsmodels dependency check: `python -c "import statsmodels; print(statsmodels.__version__)"`
</verification>

<success_criteria>
- COST-06: Estimate temporary market impact - SATISFIED
- COST-07: Estimate permanent market impact - SATISFIED
- Square-root model with temp/perm decomposition implemented
- Parameter calibration from historical data working
- Confidence levels and warnings for thin liquidity conditions
- All unit tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/02-cost-analytics/02-03-SUMMARY.md`
</output>
