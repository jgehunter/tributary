---
phase: 02-cost-analytics
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/tributary/analytics/slippage.py
  - src/tributary/analytics/shortfall.py
  - src/tributary/analytics/__init__.py
  - tests/unit/test_slippage.py
  - tests/unit/test_shortfall.py
autonomous: true

must_haves:
  truths:
    - "User can calculate slippage in basis points for any executed order"
    - "User can decompose implementation shortfall into timing, impact, and spread components"
    - "Positive slippage always means cost (unfavorable execution)"
    - "Sign conventions are consistent for buy and sell sides"
  artifacts:
    - path: "src/tributary/analytics/slippage.py"
      provides: "Slippage calculation in basis points"
      exports: ["calculate_slippage_bps"]
    - path: "src/tributary/analytics/shortfall.py"
      provides: "Implementation shortfall decomposition (Perold framework)"
      exports: ["ShortfallComponents", "decompose_implementation_shortfall"]
    - path: "tests/unit/test_slippage.py"
      provides: "Unit tests for slippage calculation"
      min_tests: 8
    - path: "tests/unit/test_shortfall.py"
      provides: "Unit tests for shortfall decomposition"
      min_tests: 10
  key_links:
    - from: "src/tributary/analytics/__init__.py"
      to: "slippage.py, shortfall.py"
      via: "module exports"
      pattern: "from tributary.analytics import calculate_slippage_bps, decompose_implementation_shortfall"
---

<objective>
Implement slippage calculation in basis points and implementation shortfall decomposition using the Perold framework.

Purpose: Provide the foundational cost measurement functions that quantify execution quality. Slippage measures the gap between expected and actual execution price. Shortfall decomposition breaks down total cost into actionable components (delay, trading impact, spread, opportunity cost).

Output: Two new analytics modules (slippage.py, shortfall.py) with comprehensive unit tests.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/02-cost-analytics/02-RESEARCH.md

# Phase 1 deliverables (available for use)
@src/tributary/analytics/benchmarks.py
@src/tributary/analytics/__init__.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Slippage Calculation Module</name>
  <files>
    src/tributary/analytics/slippage.py
    tests/unit/test_slippage.py
  </files>
  <action>
Create `slippage.py` with:

1. `calculate_slippage_bps(execution_price, benchmark_price, side)` function:
   - Formula: `(execution_price - benchmark_price) / benchmark_price * 10000`
   - For sells, flip the sign (getting less than expected is a cost)
   - Return `float('nan')` if benchmark_price is 0 or invalid
   - Convention: positive = cost (unfavorable), negative = gain (favorable)

2. Docstring with:
   - Clear explanation of sign convention
   - Args: execution_price (float), benchmark_price (float), side (str: 'buy' or 'sell')
   - Returns: float (basis points)
   - Example showing buy and sell cases

Create `test_slippage.py` with tests:
- Buy slippage positive (paid more than expected)
- Buy slippage negative (paid less - favorable)
- Sell slippage positive (received less than expected)
- Sell slippage negative (received more - favorable)
- Zero benchmark price returns NaN
- Equal prices returns 0.0
- Large slippage values (1000+ bps)
- Invalid side raises ValueError

Follow existing test patterns in tests/unit/test_benchmarks.py.
  </action>
  <verify>
    - `python -c "from tributary.analytics import calculate_slippage_bps; print(calculate_slippage_bps(102, 100, 'buy'))"`
    - Output should be 200.0 (2% = 200 bps)
    - `pytest tests/unit/test_slippage.py -v` passes all tests
  </verify>
  <done>
    - calculate_slippage_bps function correctly computes slippage in basis points
    - Sign convention: positive = cost for both buy and sell
    - 8+ unit tests passing
  </done>
</task>

<task type="auto">
  <name>Task 2: Implementation Shortfall Decomposition</name>
  <files>
    src/tributary/analytics/shortfall.py
    tests/unit/test_shortfall.py
    src/tributary/analytics/__init__.py
  </files>
  <action>
Create `shortfall.py` with:

1. `ShortfallComponents` dataclass:
   ```python
   @dataclass
   class ShortfallComponents:
       delay_cost_bps: float      # Price movement: decision -> order entry
       trading_cost_bps: float    # Price movement: order entry -> execution (market impact)
       spread_cost_bps: float     # Half-spread crossed
       opportunity_cost_bps: float # Unfilled portion cost
       total_bps: float           # Sum of components

       # Dollar amounts for transparency
       delay_cost_usd: float
       trading_cost_usd: float
       spread_cost_usd: float
       opportunity_cost_usd: float
       total_usd: float
   ```

2. `decompose_implementation_shortfall()` function:
   - Parameters: decision_price, order_entry_price, execution_prices (list), execution_sizes (list), total_order_size, closing_price, side, spread_at_entry (optional)
   - Implements Perold framework decomposition (see 02-RESEARCH.md Pattern 2)
   - Flip signs for sell orders
   - Handle edge cases: empty executions, zero notional, missing spread

3. Update `__init__.py` to export:
   - `calculate_slippage_bps` from slippage
   - `ShortfallComponents`, `decompose_implementation_shortfall` from shortfall

Create `test_shortfall.py` with tests:
- Full execution (all filled) - buy side
- Full execution (all filled) - sell side
- Partial execution (opportunity cost present)
- Zero execution (100% opportunity cost)
- Multiple fills at different prices
- No price movement (delay_cost = 0)
- Spread cost calculation
- Missing spread (spread_cost = 0)
- Sign convention verification for sells
- Empty execution lists

Follow research code patterns from 02-RESEARCH.md.
  </action>
  <verify>
    - `python -c "from tributary.analytics import ShortfallComponents, decompose_implementation_shortfall; print('OK')"`
    - `pytest tests/unit/test_shortfall.py -v` passes all tests
    - `ruff check src/tributary/analytics/` passes
  </verify>
  <done>
    - ShortfallComponents dataclass with all cost components (bps and USD)
    - decompose_implementation_shortfall correctly decomposes costs per Perold framework
    - Both modules exported from analytics package
    - 10+ unit tests passing
    - Requirements COST-04, COST-05 satisfied
  </done>
</task>

</tasks>

<verification>
After completing both tasks:
1. All 18+ unit tests pass: `pytest tests/unit/test_slippage.py tests/unit/test_shortfall.py -v`
2. Imports work cleanly: `from tributary.analytics import calculate_slippage_bps, ShortfallComponents, decompose_implementation_shortfall`
3. Lint passes: `ruff check src/tributary/analytics/`
4. Verify sign convention: buy slippage 102 vs 100 = +200 bps (cost), sell slippage 98 vs 100 = +200 bps (cost)
</verification>

<success_criteria>
- COST-04: Calculate slippage in basis points - SATISFIED
- COST-05: Decompose implementation shortfall - SATISFIED
- All unit tests pass
- Clean imports from analytics package
- Consistent sign convention (positive = cost)
</success_criteria>

<output>
After completion, create `.planning/phases/02-cost-analytics/02-01-SUMMARY.md`
</output>
