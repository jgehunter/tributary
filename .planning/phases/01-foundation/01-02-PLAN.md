---
phase: 01-foundation
plan: 02
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - src/tributary/analytics/benchmarks.py
  - src/tributary/analytics/__init__.py
  - tests/unit/test_benchmarks.py
autonomous: true

must_haves:
  truths:
    - "User can calculate VWAP for any time window and market"
    - "User can calculate TWAP for any time window and market"
    - "User can calculate arrival price (mid-price at order submission time)"
    - "Benchmarks work with data from QuestDBReader"
  artifacts:
    - path: "src/tributary/analytics/benchmarks.py"
      provides: "VWAP, TWAP, arrival price calculations"
      min_lines: 100
      exports: ["calculate_vwap", "calculate_twap", "get_arrival_price"]
    - path: "tests/unit/test_benchmarks.py"
      provides: "Unit tests for benchmark calculations"
      min_lines: 80
  key_links:
    - from: "src/tributary/analytics/benchmarks.py"
      to: "pandas DataFrame"
      via: "calculation input"
      pattern: "pd\\.DataFrame|trades_df|orderbooks_df"
    - from: "src/tributary/analytics/benchmarks.py"
      to: "QuestDBReader"
      via: "arrival price lookup"
      pattern: "reader\\.query_orderbook_snapshots|QuestDBReader"
---

<objective>
Implement core benchmark calculations: VWAP, TWAP, and arrival price.

Purpose: These benchmarks are the foundation for measuring execution quality. VWAP and TWAP are standard volume/time-weighted prices used as execution targets. Arrival price is the reference point for measuring implementation shortfall.

Output:
- `src/tributary/analytics/benchmarks.py` - Benchmark calculation functions
- Updated `src/tributary/analytics/__init__.py` - Export benchmark functions
- `tests/unit/test_benchmarks.py` - Unit tests for calculations
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/01-foundation/01-RESEARCH.md

# Depends on Plan 01 output
@.planning/phases/01-foundation/01-01-SUMMARY.md

# Reference for data structures
@src/tributary/core/models.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement VWAP calculations</name>
  <files>src/tributary/analytics/benchmarks.py</files>
  <action>
Create benchmarks module with VWAP functions:

1. `calculate_vwap(trades_df: pd.DataFrame) -> float`:
   - Standard VWAP: sum(price * size) / sum(size)
   - Input: DataFrame with 'price' and 'size' columns
   - Return float('nan') if empty or zero total volume
   - Formula from research: `(trades_df['price'] * trades_df['size']).sum() / trades_df['size'].sum()`

2. `calculate_cumulative_vwap(trades_df: pd.DataFrame) -> pd.Series`:
   - Running VWAP over time (cumulative)
   - Input: DataFrame with 'price', 'size', 'timestamp' columns
   - Sort by timestamp, then calculate cumulative sums
   - Return Series indexed same as input, with cumulative VWAP at each trade
   - Formula: `cumsum(price * size) / cumsum(size)`

3. `calculate_vwap_for_period(reader: QuestDBReader, market_id: str, token_id: str, start_time: datetime, end_time: datetime) -> float`:
   - Convenience function that queries trades and calculates VWAP
   - Uses reader.query_trades() to fetch data
   - Returns float('nan') if no trades in period

Type hints: Use datetime for time params, Optional where appropriate.
  </action>
  <verify>
- File exists: `src/tributary/analytics/benchmarks.py`
- `ruff check src/tributary/analytics/benchmarks.py` passes
- All three VWAP functions defined with proper type hints
  </verify>
  <done>
VWAP calculation functions exist: single value, cumulative series, and convenience wrapper with reader.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement TWAP and arrival price calculations</name>
  <files>
    src/tributary/analytics/benchmarks.py
    src/tributary/analytics/__init__.py
  </files>
  <action>
Add TWAP and arrival price functions to benchmarks.py:

1. `calculate_twap(trades_df: pd.DataFrame, interval: str = "1min") -> float`:
   - Time-weighted average price from trades
   - Resample to regular intervals, take last price per interval
   - Return mean of interval prices
   - Uses: `df.set_index('timestamp')['price'].resample(interval).last().dropna().mean()`
   - Return float('nan') if empty

2. `calculate_twap_from_orderbooks(orderbooks_df: pd.DataFrame, interval: str = "1min") -> float`:
   - TWAP from orderbook mid-prices (more accurate for illiquid markets)
   - Same resampling logic but uses 'mid_price' column
   - Return float('nan') if empty

3. `get_arrival_price(reader: QuestDBReader, market_id: str, token_id: str, order_time: datetime, lookback_seconds: int = 5) -> Optional[float]`:
   - Get mid-price at order submission time
   - Query orderbook snapshot closest to (but not after) order_time
   - Search window: order_time - lookback_seconds to order_time
   - Return None if no snapshot found in window
   - SQL: ORDER BY timestamp DESC LIMIT 1 to get closest snapshot

4. Update `src/tributary/analytics/__init__.py`:
   - Add exports for all benchmark functions:
     - calculate_vwap, calculate_cumulative_vwap, calculate_vwap_for_period
     - calculate_twap, calculate_twap_from_orderbooks
     - get_arrival_price
  </action>
  <verify>
- `ruff check src/tributary/analytics/` passes
- `from tributary.analytics import calculate_vwap, calculate_twap, get_arrival_price` works
- All functions have proper type hints and docstrings
  </verify>
  <done>
TWAP calculations (trade-based and orderbook-based) and arrival price lookup are implemented.
All benchmark functions are exported from analytics module.
  </done>
</task>

<task type="auto">
  <name>Task 3: Add unit tests for benchmark calculations</name>
  <files>tests/unit/test_benchmarks.py</files>
  <action>
Create comprehensive unit tests for all benchmark functions:

1. VWAP tests:
   - `test_calculate_vwap_simple` - known values: trades at [100, 200] with sizes [10, 20] -> VWAP = 166.67
   - `test_calculate_vwap_empty_df` - returns NaN for empty DataFrame
   - `test_calculate_vwap_zero_volume` - returns NaN if all sizes are 0
   - `test_cumulative_vwap_ordering` - cumulative VWAP changes over time correctly

2. TWAP tests:
   - `test_calculate_twap_uniform_intervals` - equal-spaced trades
   - `test_calculate_twap_sparse_intervals` - some intervals have no trades
   - `test_calculate_twap_empty_df` - returns NaN
   - `test_twap_from_orderbooks` - uses mid_price column

3. Arrival price tests:
   - `test_get_arrival_price_exact_match` - snapshot at exact order time
   - `test_get_arrival_price_closest_before` - returns snapshot before order time
   - `test_get_arrival_price_none_found` - returns None if no snapshot in window
   - Mock reader.query_orderbook_snapshots for these tests

Use pytest fixtures to create sample DataFrames. Use np.isnan() to check NaN returns.
  </action>
  <verify>
- `pytest tests/unit/test_benchmarks.py -v` passes
- Tests cover VWAP, TWAP, and arrival price
- Edge cases (empty data, zero volume) are tested
  </verify>
  <done>
Unit tests pass for all benchmark calculations including edge cases.
  </done>
</task>

</tasks>

<verification>
After all tasks complete:

1. Module structure:
   ```
   src/tributary/analytics/
   |-- __init__.py
   |-- reader.py
   |-- benchmarks.py
   ```

2. Import test:
   ```bash
   python -c "from tributary.analytics import QuestDBReader, calculate_vwap, calculate_twap, get_arrival_price; print('Imports OK')"
   ```

3. Unit tests:
   ```bash
   pytest tests/unit/test_benchmarks.py -v
   ```

4. Full test suite:
   ```bash
   pytest tests/unit/ -v
   ```

5. Lint check:
   ```bash
   ruff check src/tributary/analytics/
   ```
</verification>

<success_criteria>
- calculate_vwap() computes volume-weighted average price
- calculate_cumulative_vwap() returns running VWAP series
- calculate_twap() computes time-weighted average price
- calculate_twap_from_orderbooks() computes TWAP from mid-prices
- get_arrival_price() returns mid-price at order submission time
- All functions handle empty/edge cases gracefully (return NaN or None)
- Unit tests pass without requiring real database
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-02-SUMMARY.md`
</output>
