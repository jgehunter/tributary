{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Liquidity Analysis\n",
    "\n",
    "Understand how liquid each orderbook is and what it costs to trade.\n",
    "\n",
    "**Unit of analysis**: The orderbook (each token_id)\n",
    "\n",
    "**Key questions**:\n",
    "1. Which orderbooks are liquid enough to trade?\n",
    "2. What does it cost to execute different trade sizes?\n",
    "3. When is liquidity best/worst?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from sqlalchemy import create_engine\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "pd.set_option('display.max_colwidth', 80)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "\n",
    "engine = create_engine('postgresql://admin:quest@localhost:8812/qdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build token_id -> context mapping\n",
    "markets_df = pd.read_sql(\"SELECT market_id, market_slug, question, metadata FROM markets\", engine)\n",
    "\n",
    "token_info = {}\n",
    "for _, row in markets_df.iterrows():\n",
    "    try:\n",
    "        meta = json.loads(row['metadata']) if isinstance(row['metadata'], str) else row['metadata']\n",
    "        outcomes = meta.get('outcomes', ['Yes', 'No'])\n",
    "        token_ids = meta.get('clob_token_ids', [])\n",
    "        \n",
    "        for i, tid in enumerate(token_ids):\n",
    "            token_info[tid] = {\n",
    "                'market_slug': row['market_slug'],\n",
    "                'question': row['question'][:60],\n",
    "                'outcome': outcomes[i] if i < len(outcomes) else f'Outcome_{i}'\n",
    "            }\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "def get_label(token_id):\n",
    "    info = token_info.get(token_id, {})\n",
    "    return f\"{info.get('question', '?')[:40]}... ({info.get('outcome', '?')})\"\n",
    "\n",
    "print(f\"Token mappings: {len(token_info)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Liquidity Metrics per Orderbook\n",
    "\n",
    "Core metrics: spread, depth at top of book, total depth.\n",
    "\n",
    "**Note**: Orderbooks with one empty side (no bids or no asks) have invalid spreads and are flagged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate liquidity metrics per orderbook\n",
    "# Include best_bid/best_ask to detect one-sided orderbooks\n",
    "liquidity_query = \"\"\"\n",
    "SELECT \n",
    "    token_id,\n",
    "    avg(spread) as avg_spread,\n",
    "    avg(spread_bps) as avg_spread_bps,\n",
    "    avg(best_bid) as avg_best_bid,\n",
    "    avg(best_ask) as avg_best_ask,\n",
    "    avg(bid_size) as avg_bid_size_top,\n",
    "    avg(ask_size) as avg_ask_size_top,\n",
    "    avg(total_bid_volume) as avg_bid_depth,\n",
    "    avg(total_ask_volume) as avg_ask_depth,\n",
    "    avg(mid_price) as avg_mid_price,\n",
    "    count() as n_snapshots\n",
    "FROM orderbook_snapshots\n",
    "WHERE timestamp > dateadd('d', -7, now())\n",
    "\"\"\"\n",
    "\n",
    "df_liq = pd.read_sql(liquidity_query, engine)\n",
    "\n",
    "# Add context\n",
    "df_liq['label'] = df_liq['token_id'].apply(get_label)\n",
    "df_liq['outcome'] = df_liq['token_id'].map(lambda x: token_info.get(x, {}).get('outcome', '?'))\n",
    "\n",
    "# Detect one-sided orderbooks (bid=0 means no bids, ask=1 means no asks)\n",
    "df_liq['has_bids'] = df_liq['avg_best_bid'] > 0.001\n",
    "df_liq['has_asks'] = df_liq['avg_best_ask'] < 0.999\n",
    "df_liq['is_two_sided'] = df_liq['has_bids'] & df_liq['has_asks']\n",
    "\n",
    "# Compute derived metrics\n",
    "df_liq['top_of_book_depth'] = df_liq['avg_bid_size_top'] + df_liq['avg_ask_size_top']\n",
    "df_liq['total_depth'] = df_liq['avg_bid_depth'] + df_liq['avg_ask_depth']\n",
    "\n",
    "# For one-sided orderbooks, spread_bps is meaningless - set to NaN\n",
    "df_liq.loc[~df_liq['is_two_sided'], 'avg_spread_bps'] = np.nan\n",
    "\n",
    "# Summary\n",
    "n_total = len(df_liq)\n",
    "n_two_sided = df_liq['is_two_sided'].sum()\n",
    "n_one_sided = n_total - n_two_sided\n",
    "\n",
    "print(f\"Total orderbooks: {n_total}\")\n",
    "print(f\"  Two-sided (tradeable): {n_two_sided}\")\n",
    "print(f\"  One-sided (not tradeable): {n_one_sided}\")\n",
    "\n",
    "# Show all orderbooks with status\n",
    "df_liq_sorted = df_liq.sort_values('avg_spread_bps', na_position='last')\n",
    "print(f\"\\nOrderbook Summary:\")\n",
    "display(df_liq_sorted[['label', 'is_two_sided', 'avg_mid_price', 'avg_spread_bps', 'top_of_book_depth']].round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Liquidity Ranking (Two-Sided Only)\n",
    "\n",
    "**Tradeable** = two-sided + tight spread + sufficient depth.\n",
    "\n",
    "We only rank orderbooks that have both bids and asks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to two-sided orderbooks only\n",
    "df_rank = df_liq[df_liq['is_two_sided']].copy()\n",
    "\n",
    "if len(df_rank) == 0:\n",
    "    print(\"No two-sided orderbooks available for ranking.\")\n",
    "else:\n",
    "    # Spread score: 0 = worst (widest), 1 = best (tightest)\n",
    "    spread_min = df_rank['avg_spread_bps'].min()\n",
    "    spread_max = df_rank['avg_spread_bps'].max()\n",
    "    if spread_max > spread_min:\n",
    "        df_rank['spread_score'] = 1 - (df_rank['avg_spread_bps'] - spread_min) / (spread_max - spread_min)\n",
    "    else:\n",
    "        df_rank['spread_score'] = 0.5\n",
    "\n",
    "    # Depth score: 0 = worst (shallowest), 1 = best (deepest)\n",
    "    depth_min = df_rank['top_of_book_depth'].min()\n",
    "    depth_max = df_rank['top_of_book_depth'].max()\n",
    "    if depth_max > depth_min:\n",
    "        df_rank['depth_score'] = (df_rank['top_of_book_depth'] - depth_min) / (depth_max - depth_min)\n",
    "    else:\n",
    "        df_rank['depth_score'] = 0.5\n",
    "\n",
    "    # Combined score (70% spread, 30% depth)\n",
    "    df_rank['liquidity_score'] = 0.7 * df_rank['spread_score'] + 0.3 * df_rank['depth_score']\n",
    "\n",
    "    # Classify\n",
    "    def classify_liquidity(score):\n",
    "        if pd.isna(score): return 'N/A'\n",
    "        if score >= 0.7: return 'Good'\n",
    "        elif score >= 0.4: return 'Fair'\n",
    "        else: return 'Poor'\n",
    "\n",
    "    df_rank['liquidity_class'] = df_rank['liquidity_score'].apply(classify_liquidity)\n",
    "    df_rank = df_rank.sort_values('liquidity_score', ascending=False)\n",
    "\n",
    "    print(f\"Liquidity Ranking ({len(df_rank)} two-sided orderbooks):\")\n",
    "    display(df_rank[['label', 'avg_spread_bps', 'top_of_book_depth', 'liquidity_score', 'liquidity_class']].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_rank) > 0:\n",
    "    # Visualize liquidity classes\n",
    "    class_counts = df_rank['liquidity_class'].value_counts()\n",
    "    print(\"Liquidity Distribution (two-sided only):\")\n",
    "    for cls, cnt in class_counts.items():\n",
    "        print(f\"  {cls}: {cnt} orderbooks ({cnt/len(df_rank)*100:.0f}%)\")\n",
    "\n",
    "    # Bar chart\n",
    "    fig = px.bar(\n",
    "        df_rank.head(15),\n",
    "        x='label',\n",
    "        y='liquidity_score',\n",
    "        color='liquidity_class',\n",
    "        color_discrete_map={'Good': 'green', 'Fair': 'orange', 'Poor': 'red'},\n",
    "        title='Top Orderbooks by Liquidity Score (Two-Sided Only)'\n",
    "    )\n",
    "    fig.update_layout(height=450, xaxis_tickangle=-45, xaxis_title='', yaxis_title='Liquidity Score')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Execution Cost Analysis\n",
    "\n",
    "**The key question**: What does it cost to execute $100, $500, $1000?\n",
    "\n",
    "Uses full orderbook depth to simulate execution. One-sided orderbooks return N/A for the empty side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_execution_cost(prices, sizes, target_value, side='buy'):\n",
    "    \"\"\"\n",
    "    Compute execution cost for a target dollar value.\n",
    "    Returns: (avg_price, slippage_bps, filled_value) or None if can't fill.\n",
    "    \"\"\"\n",
    "    if not prices or not sizes or len(prices) != len(sizes):\n",
    "        return None\n",
    "    \n",
    "    # Filter out zero prices/sizes\n",
    "    valid = [(p, s) for p, s in zip(prices, sizes) if p > 0 and s > 0]\n",
    "    if not valid:\n",
    "        return None\n",
    "    \n",
    "    if side == 'buy':\n",
    "        order = sorted(valid, key=lambda x: x[0])  # ascending (best ask first)\n",
    "    else:\n",
    "        order = sorted(valid, key=lambda x: x[0], reverse=True)  # descending (best bid first)\n",
    "    \n",
    "    filled_value = 0\n",
    "    filled_qty = 0\n",
    "    best_price = order[0][0]\n",
    "    \n",
    "    for price, size in order:\n",
    "        level_value = price * size\n",
    "        remaining = target_value - filled_value\n",
    "        \n",
    "        if level_value >= remaining:\n",
    "            qty_needed = remaining / price\n",
    "            filled_qty += qty_needed\n",
    "            filled_value += remaining\n",
    "            break\n",
    "        else:\n",
    "            filled_qty += size\n",
    "            filled_value += level_value\n",
    "    \n",
    "    if filled_value < target_value * 0.99:\n",
    "        return None\n",
    "    \n",
    "    avg_price = filled_value / filled_qty if filled_qty > 0 else None\n",
    "    if avg_price is None:\n",
    "        return None\n",
    "    \n",
    "    if side == 'buy':\n",
    "        slippage_bps = (avg_price - best_price) / best_price * 10000 if best_price > 0 else 0\n",
    "    else:\n",
    "        slippage_bps = (best_price - avg_price) / best_price * 10000 if best_price > 0 else 0\n",
    "    \n",
    "    return (avg_price, slippage_bps, filled_value)\n",
    "\n",
    "print(\"Execution cost function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get recent snapshots with full depth\n",
    "depth_query = \"\"\"\n",
    "SELECT \n",
    "    token_id,\n",
    "    bid_prices,\n",
    "    bid_sizes,\n",
    "    ask_prices,\n",
    "    ask_sizes,\n",
    "    best_bid,\n",
    "    best_ask,\n",
    "    mid_price,\n",
    "    spread_bps\n",
    "FROM orderbook_snapshots\n",
    "WHERE timestamp > dateadd('h', -1, now())\n",
    "\"\"\"\n",
    "\n",
    "df_depth = pd.read_sql(depth_query, engine)\n",
    "print(f\"Recent snapshots: {len(df_depth)}\")\n",
    "\n",
    "def safe_json_loads(x):\n",
    "    try:\n",
    "        return json.loads(x) if isinstance(x, str) else (x if x else [])\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "df_depth['bid_prices'] = df_depth['bid_prices'].apply(safe_json_loads)\n",
    "df_depth['bid_sizes'] = df_depth['bid_sizes'].apply(safe_json_loads)\n",
    "df_depth['ask_prices'] = df_depth['ask_prices'].apply(safe_json_loads)\n",
    "df_depth['ask_sizes'] = df_depth['ask_sizes'].apply(safe_json_loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute execution costs\n",
    "trade_sizes = [100, 500, 1000]\n",
    "\n",
    "results = []\n",
    "for token_id in df_depth['token_id'].unique():\n",
    "    token_snaps = df_depth[df_depth['token_id'] == token_id]\n",
    "    if len(token_snaps) == 0:\n",
    "        continue\n",
    "    \n",
    "    snap = token_snaps.iloc[-1]\n",
    "    \n",
    "    # Detect one-sided\n",
    "    has_bids = snap['best_bid'] > 0.001\n",
    "    has_asks = snap['best_ask'] < 0.999\n",
    "    is_two_sided = has_bids and has_asks\n",
    "    \n",
    "    row = {\n",
    "        'token_id': token_id,\n",
    "        'label': get_label(token_id),\n",
    "        'mid_price': snap['mid_price'],\n",
    "        'is_two_sided': is_two_sided,\n",
    "        'spread_bps': snap['spread_bps'] if is_two_sided else np.nan\n",
    "    }\n",
    "    \n",
    "    # Buy costs (needs asks)\n",
    "    for size in trade_sizes:\n",
    "        if has_asks:\n",
    "            result = compute_execution_cost(snap['ask_prices'], snap['ask_sizes'], size, 'buy')\n",
    "            row[f'buy_{size}_slippage_bps'] = result[1] if result else np.nan\n",
    "        else:\n",
    "            row[f'buy_{size}_slippage_bps'] = np.nan\n",
    "    \n",
    "    # Sell costs (needs bids)\n",
    "    for size in trade_sizes:\n",
    "        if has_bids:\n",
    "            result = compute_execution_cost(snap['bid_prices'], snap['bid_sizes'], size, 'sell')\n",
    "            row[f'sell_{size}_slippage_bps'] = result[1] if result else np.nan\n",
    "        else:\n",
    "            row[f'sell_{size}_slippage_bps'] = np.nan\n",
    "    \n",
    "    results.append(row)\n",
    "\n",
    "df_exec = pd.DataFrame(results)\n",
    "print(f\"Execution cost analysis: {len(df_exec)} orderbooks ({df_exec['is_two_sided'].sum()} two-sided)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display execution costs (two-sided only for meaningful comparison)\n",
    "df_exec_valid = df_exec[df_exec['is_two_sided']].copy()\n",
    "\n",
    "if len(df_exec_valid) > 0:\n",
    "    # Total cost = spread/2 + slippage\n",
    "    df_exec_valid['total_cost_100_bps'] = df_exec_valid['spread_bps']/2 + df_exec_valid['buy_100_slippage_bps'].fillna(0)\n",
    "    df_exec_valid['total_cost_500_bps'] = df_exec_valid['spread_bps']/2 + df_exec_valid['buy_500_slippage_bps'].fillna(0)\n",
    "    df_exec_valid['total_cost_1000_bps'] = df_exec_valid['spread_bps']/2 + df_exec_valid['buy_1000_slippage_bps'].fillna(0)\n",
    "    \n",
    "    df_exec_valid = df_exec_valid.sort_values('total_cost_100_bps')\n",
    "    \n",
    "    print(\"Execution Cost by Trade Size (two-sided orderbooks):\")\n",
    "    print(\"(Total cost = half spread + slippage)\\n\")\n",
    "    display(df_exec_valid[['label', 'spread_bps', 'total_cost_100_bps', 'total_cost_500_bps', 'total_cost_1000_bps']].round(1))\n",
    "else:\n",
    "    print(\"No two-sided orderbooks available for execution cost analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize execution cost vs trade size\n",
    "if len(df_exec_valid) > 0:\n",
    "    top_orderbooks = df_exec_valid.head(8)['token_id'].tolist()\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    for tid in top_orderbooks:\n",
    "        row = df_exec_valid[df_exec_valid['token_id'] == tid].iloc[0]\n",
    "        costs = [\n",
    "            row['total_cost_100_bps'],\n",
    "            row['total_cost_500_bps'],\n",
    "            row['total_cost_1000_bps']\n",
    "        ]\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[100, 500, 1000],\n",
    "            y=costs,\n",
    "            mode='lines+markers',\n",
    "            name=row['label'][:30]\n",
    "        ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Execution Cost vs Trade Size (Top Two-Sided Orderbooks)',\n",
    "        xaxis_title='Trade Size (USD)',\n",
    "        yaxis_title='Total Cost (bps)',\n",
    "        height=450\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Intraday Liquidity Patterns\n",
    "\n",
    "When is liquidity best/worst? (Two-sided orderbooks only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intraday patterns - only include valid two-sided snapshots\n",
    "intraday_query = \"\"\"\n",
    "SELECT \n",
    "    hour(timestamp) as hour_utc,\n",
    "    avg(spread_bps) as avg_spread_bps,\n",
    "    avg(total_bid_volume + total_ask_volume) as avg_depth,\n",
    "    count() as n_obs\n",
    "FROM orderbook_snapshots\n",
    "WHERE timestamp > dateadd('d', -7, now())\n",
    "  AND best_bid > 0.001 AND best_ask < 0.999\n",
    "ORDER BY hour_utc\n",
    "\"\"\"\n",
    "\n",
    "df_intraday = pd.read_sql(intraday_query, engine)\n",
    "\n",
    "if len(df_intraday) > 0:\n",
    "    best_hour = df_intraday.loc[df_intraday['avg_spread_bps'].idxmin()]\n",
    "    worst_hour = df_intraday.loc[df_intraday['avg_spread_bps'].idxmax()]\n",
    "    \n",
    "    print(f\"Best hour (tightest spread): {int(best_hour['hour_utc'])}:00 UTC - {best_hour['avg_spread_bps']:.0f} bps\")\n",
    "    print(f\"Worst hour (widest spread): {int(worst_hour['hour_utc'])}:00 UTC - {worst_hour['avg_spread_bps']:.0f} bps\")\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=df_intraday['hour_utc'],\n",
    "        y=df_intraday['avg_spread_bps'],\n",
    "        marker_color='steelblue'\n",
    "    ))\n",
    "    fig.add_hline(y=df_intraday['avg_spread_bps'].mean(), line_dash='dash', line_color='red')\n",
    "    fig.update_layout(\n",
    "        title='Average Spread by Hour (Two-Sided Orderbooks Only)',\n",
    "        xaxis_title='Hour (UTC)',\n",
    "        yaxis_title='Avg Spread (bps)',\n",
    "        height=400\n",
    "    )\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"No intraday data available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Volume vs Liquidity\n",
    "\n",
    "Does more trading volume correlate with better liquidity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get trading volume per orderbook\n",
    "volume_query = \"\"\"\n",
    "SELECT \n",
    "    token_id,\n",
    "    sum(value) as total_volume,\n",
    "    count() as n_trades\n",
    "FROM trades\n",
    "WHERE timestamp > dateadd('d', -7, now())\n",
    "\"\"\"\n",
    "\n",
    "df_vol = pd.read_sql(volume_query, engine)\n",
    "\n",
    "# Merge with liquidity data (two-sided only)\n",
    "df_combined = df_liq[df_liq['is_two_sided']].merge(df_vol, on='token_id', how='left')\n",
    "df_combined['total_volume'] = df_combined['total_volume'].fillna(0)\n",
    "df_combined['n_trades'] = df_combined['n_trades'].fillna(0)\n",
    "\n",
    "# Filter to orderbooks with trading activity\n",
    "df_active = df_combined[df_combined['n_trades'] > 10].copy()\n",
    "\n",
    "if len(df_active) > 2:\n",
    "    from scipy import stats\n",
    "    # Drop NaN spread values\n",
    "    df_corr = df_active.dropna(subset=['avg_spread_bps'])\n",
    "    if len(df_corr) > 2:\n",
    "        corr, pval = stats.spearmanr(df_corr['total_volume'], df_corr['avg_spread_bps'])\n",
    "        print(f\"Spearman correlation (volume vs spread): {corr:.3f} (p={pval:.3f})\")\n",
    "        if corr < 0:\n",
    "            print(\"Higher volume orderbooks tend to have tighter spreads.\")\n",
    "        else:\n",
    "            print(\"No clear relationship between volume and spread.\")\n",
    "        \n",
    "        fig = px.scatter(\n",
    "            df_corr,\n",
    "            x='total_volume',\n",
    "            y='avg_spread_bps',\n",
    "            hover_name='label',\n",
    "            size='n_trades',\n",
    "            title='Trading Volume vs Spread (Two-Sided Orderbooks)',\n",
    "            labels={'total_volume': 'Total Volume (7d, USD)', 'avg_spread_bps': 'Avg Spread (bps)'}\n",
    "        )\n",
    "        fig.update_xaxes(type='log')\n",
    "        fig.update_layout(height=450)\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(\"Not enough data for correlation analysis.\")\n",
    "else:\n",
    "    print(\"Not enough active two-sided orderbooks for analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"LIQUIDITY SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nTotal orderbooks: {len(df_liq)}\")\n",
    "print(f\"  Two-sided (tradeable): {df_liq['is_two_sided'].sum()}\")\n",
    "print(f\"  One-sided (not tradeable): {(~df_liq['is_two_sided']).sum()}\")\n",
    "\n",
    "if 'df_rank' in dir() and len(df_rank) > 0:\n",
    "    good_liq = df_rank[df_rank['liquidity_class'] == 'Good']\n",
    "    print(f\"\\nOrderbooks with GOOD liquidity: {len(good_liq)}\")\n",
    "    for _, row in good_liq.head(5).iterrows():\n",
    "        print(f\"  - {row['label']}\")\n",
    "        print(f\"    Spread: {row['avg_spread_bps']:.0f} bps, Depth: {row['top_of_book_depth']:.0f}\")\n",
    "\n",
    "if 'df_exec_valid' in dir() and len(df_exec_valid) > 0:\n",
    "    print(f\"\\nExecution costs (best orderbook):\")\n",
    "    best = df_exec_valid.iloc[0]\n",
    "    print(f\"  $100 trade: {best['total_cost_100_bps']:.0f} bps\")\n",
    "    print(f\"  $500 trade: {best['total_cost_500_bps']:.0f} bps\")\n",
    "    print(f\"  $1000 trade: {best['total_cost_1000_bps']:.0f} bps\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.dispose()\n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
